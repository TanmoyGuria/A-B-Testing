# ğŸ“Š A/B Testing for Marketing Campaigns  
### **Python Project | June 2025**

This project evaluates the performance of two marketing campaign variants (A & B) using statistical A/B testing. The goal is to determine which campaign leads to higher user engagement and conversions, enabling data-driven marketing decisions.

---

## ğŸš€ Objective
To analyze campaign performance data, compare conversion rates between Variant A and Variant B, and statistically validate which version performs better.

---

## ğŸ›  Tech Stack
- **Python 3**
- **Pandas, NumPy** â€“ Data manipulation  
- **Matplotlib / Seaborn** â€“ Data visualization  
- **SciPy (stats)** â€“ Hypothesis testing  

---

## ğŸ“ˆ Project Workflow

### 1ï¸âƒ£ Data Import & Cleaning
- Loaded campaign datasets  
- Checked and handled missing values  
- Standardized metrics such as clicks, impressions, and conversions  

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)
- Compared engagement patterns for A & B  
- Visualized conversion trends and click-through rates  

### 3ï¸âƒ£ Hypothesis Testing
- **Hâ‚€:** No difference in conversion rates  
- **Hâ‚:** Conversion rates differ  
- Performed **Z-test / T-test**  
- Calculated **p-values**, **uplift**, **confidence intervals**

### 4ï¸âƒ£ Result Interpretation
- Determined the winning variant  
- Estimated uplift in conversions  
- Provided recommendations for scaling the better campaign

---

## ğŸ“Š Key Insights
- Measured difference in conversion performance  
- Verified statistical significance  
- Quantified marketing uplift  
- Delivered ROI-driven recommendations  

---
